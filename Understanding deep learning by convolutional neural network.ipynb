{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding deep learning by convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoint/srcnn_21/SRCNN.model-2550000\n"
     ]
    }
   ],
   "source": [
    "#Resetting the graph (just in case something in memory)\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "#Load the trained model\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.import_meta_graph('checkpoint/srcnn_21/SRCNN.model-2550000.meta')\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoint/srcnn_21/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of first layer: (9, 9, 1, 64)\n",
      "Number of filters: 64\n",
      "Size of filters: 9x9\n",
      "Value of 1st filter:\n",
      "[[[  5.36652049e-04]\n",
      "  [ -1.92750490e-03]\n",
      "  [ -9.05649329e-04]\n",
      "  [ -2.14432506e-03]\n",
      "  [ -2.30144011e-04]\n",
      "  [  1.08357007e-03]\n",
      "  [  8.34148668e-04]\n",
      "  [ -1.30601658e-03]\n",
      "  [  2.28613804e-04]]\n",
      "\n",
      " [[ -4.72397660e-04]\n",
      "  [  8.06383905e-04]\n",
      "  [ -1.22601967e-04]\n",
      "  [  2.69839395e-04]\n",
      "  [  9.72096241e-05]\n",
      "  [  1.33433123e-03]\n",
      "  [  2.35864893e-03]\n",
      "  [  6.15326047e-04]\n",
      "  [ -1.17814029e-03]]\n",
      "\n",
      " [[  4.03551967e-04]\n",
      "  [  2.67060939e-04]\n",
      "  [  5.07810677e-04]\n",
      "  [  1.96350433e-04]\n",
      "  [ -6.82775339e-04]\n",
      "  [  3.03902489e-04]\n",
      "  [ -1.11097463e-04]\n",
      "  [ -8.01772345e-04]\n",
      "  [ -5.23039605e-04]]\n",
      "\n",
      " [[ -7.90755381e-04]\n",
      "  [ -1.21356174e-03]\n",
      "  [  1.72860897e-03]\n",
      "  [ -7.30513129e-04]\n",
      "  [ -8.74867546e-04]\n",
      "  [ -5.75013401e-04]\n",
      "  [ -1.03905877e-04]\n",
      "  [  1.34037598e-03]\n",
      "  [ -1.96215743e-03]]\n",
      "\n",
      " [[ -2.20159930e-03]\n",
      "  [ -8.35747458e-04]\n",
      "  [ -3.95902207e-05]\n",
      "  [ -1.51644053e-03]\n",
      "  [ -5.25141426e-04]\n",
      "  [  3.90667585e-04]\n",
      "  [  6.40353392e-05]\n",
      "  [  1.28647618e-04]\n",
      "  [  4.38962219e-04]]\n",
      "\n",
      " [[  9.15640849e-04]\n",
      "  [  5.16444386e-04]\n",
      "  [  1.03193510e-03]\n",
      "  [  1.39399734e-03]\n",
      "  [  6.77759061e-04]\n",
      "  [  2.25597760e-04]\n",
      "  [ -5.01868082e-04]\n",
      "  [  1.78563769e-03]\n",
      "  [  2.30049738e-03]]\n",
      "\n",
      " [[  1.71651749e-03]\n",
      "  [ -7.60289899e-04]\n",
      "  [  8.62600282e-05]\n",
      "  [ -4.95993940e-04]\n",
      "  [ -1.59400588e-04]\n",
      "  [  1.11538408e-04]\n",
      "  [ -1.52063178e-04]\n",
      "  [ -7.74750719e-04]\n",
      "  [  1.81759664e-04]]\n",
      "\n",
      " [[ -2.84049835e-04]\n",
      "  [ -5.97396138e-05]\n",
      "  [  5.67003852e-04]\n",
      "  [ -8.50154203e-04]\n",
      "  [ -9.99700627e-04]\n",
      "  [  6.43076841e-04]\n",
      "  [ -1.07030559e-03]\n",
      "  [ -2.49877310e-04]\n",
      "  [ -1.93921686e-03]]\n",
      "\n",
      " [[ -3.91599664e-04]\n",
      "  [ -1.58344221e-04]\n",
      "  [  2.79430882e-04]\n",
      "  [  7.44523946e-04]\n",
      "  [  1.21954409e-03]\n",
      "  [ -5.11598366e-04]\n",
      "  [ -9.77428630e-04]\n",
      "  [ -1.68854982e-04]\n",
      "  [ -3.05923430e-04]]]\n",
      "Value of 10th bias:\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#Parsing the weights of the first convolutional layer\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "w1 = sess.run('w1:0')\n",
    "b1 = sess.run('b1:0')\n",
    "sess.close()\n",
    "print('Shape of first layer: ' + str(w1.shape))\n",
    "print('Number of filters: ' + str(w1.shape[3]))\n",
    "print('Size of filters: ' + str(w1.shape[0]) + 'x' + str(w1.shape[1]))\n",
    "print('Value of 1st filter:')\n",
    "print(w1[:,:,:,0])\n",
    "print('Value of 10th bias:')\n",
    "print(b1[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#Parsing the weights of the second convolutional layer\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "w2 = sess.run('w2:0')\n",
    "b2 = sess.run('b2:0')\n",
    "sess.close()\n",
    "print('Shape of second layer: ' + str(w2.shape))\n",
    "print('Number of filters: ' + str(w2.shape[3]))\n",
    "print('Size of filters: ' + str(w2.shape[0]) + 'x' + str(w2.shape[1]))\n",
    "print('Value of 5th filter:')\n",
    "print(w2[:,:,:,4])\n",
    "print('Value of 6th bias:')\n",
    "print(b2[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#Parsing the weights of the third convolutional layer\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "w3 = sess.run('w3:0')\n",
    "b3 = sess.run('b3:0')\n",
    "sess.close()\n",
    "print('Shape of second layer: ' + str(w3.shape))\n",
    "print('Number of filters: ' + str(w3.shape[3]))\n",
    "print('Size of filters: ' + str(w3.shape[0]) + 'x' + str(w3.shape[1]))\n",
    "print('Value of 1st filter:')\n",
    "print(w3[:,:,:,0])\n",
    "print('Value of 1st bias:')\n",
    "print(b3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matrix operations\n",
    "v = [1, 2, 3, 4]\n",
    "v = np.asarray(v)\n",
    "v = np.reshape(v, (-1, 2))\n",
    "v += 2\n",
    "v2 = v\n",
    "v3 = v + v2\n",
    "v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performn a 2d convolution on a 2d matrix with a given filter\n",
    "import imageio\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "butterfly_image = \"butterfly_GT.bmp\"\n",
    "image = np.array(imageio.imread(butterfly_image, flatten=False))\n",
    "#Just take one channel to make 2d\n",
    "image = image[:,:,0].astype(np.float32)\n",
    "fil = tf.Variable(tf.random_normal([9, 9, 1, 1], stddev=1e-3, seed=1), name='filter')\n",
    "image = tf.Variable(tf.random_normal([9, 9, 1, 1], stddev=1, seed=1, mean=10), name='filter')\n",
    "conv = tf.nn.conv2d(input=image,filter=fil, strides = [1,1,1,1], padding = 'SAME')\n",
    "conv = tf.nn.relu(conv)\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "a = conv\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
